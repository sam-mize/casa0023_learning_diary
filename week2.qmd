---
title: "January 20th, 2026"
---

# Summary

Remote Sensing (since we’re mostly remotely sensing Earth, used interchangeably with “Earth Observation”) is acquisition of information from a distance using sensors. Typically, we’ll be working with data from satellites, although planes, drones, and anything else with any kind of sensor could potentially be used. Lidar data is point clouds, but we’ll typically be working with raster data. Even if we do use Lidar, it can usually be converted to a raster heightmap. A variety of observation satellites provide raster data with varying resolutions analogous to more typical video data:

1.  Spatial Resolution (10\~60m depending on source and spectral band) ≈ video resolution
2.  Spectral Resolution (visible plus longer and sometimes shorter bands) ≈ color channels
3.  Temporal Resolution (1\~16 days for satellite) ≈ frame rate
4.  Radiometric Resolution (4\~12 bits maybe) ≈ bit depth

Earth’s atmosphere interferes differently with transmission of different wavelengths of light. Typically, we’ll be working with data which has been processed to control for those effects and “reflect” the surface of Earth as if the atmosphere was perfectly transparent to all wavelengths. Sometimes things that appear similar to our eyes affect light outside the visible spectrum very differently, allowing them to be easily distinguished by a specific spectral band. In other cases more subtle differences in a variety of frequency bands (a “spectral signature”), analogous to a frequency-response in acoustics, circuit analysis, vibration analysis, or controls engineering, might distinguish them. A trivial example presented in the introductory lecture and practical is that foliage appears very bright in the near infrared (NIR) band, but dark in blue and green.

\
In the lecture, it was recommended to use multiple tiles from time-adjacent passes and take the median value for each pixel. Why? If you’re working with 4-bit radiometric resolution and you have \[B1111, B1111, B1111, B1111, B1001, B1000, B1000\], you don’t want B1111 = 15 unless you’re studying clouds, and why use B1000 = 8 when you can use 8.33? Presumably everything is getting converted to floating point arrays anyway for analysis?

#  Applications

@perssonTreeSpeciesClassification2018 trained a random forest model to predict specific tree species using various sets of frequency bands available from Sentinel-2 to narrow down which specific bands are most important for that task in the context of central Sweden. They found that the set of 13 spectral bands provided reasonably good accuracy, but stressed the importance of using imagery from the seasons at which the foliage is most distinguishable, in the early spring, late spring, and fall. Just as mentioned in the intro lecture, the researchers derived spectral signatures characteristic of each species of interest. The results here are interesting and maybe useful in Sweden or other places where large areas of forests are mostly the same species. North America, especially east of the Rocky Mountains has very mixed forests which would likely not be distinguishable without better spatial resolution. 

\[This\]([https://www.github.com/sentinel-hub/natural-color)\[https://www.github.com/sentinel-hub/natural-color](https://www.github.com/sentinel-hub/natural-color)[https://www.github.com/sentinel-hub/natural-color)) contains some examples and scripts developed to transform Sentinel color channels into more natural (to human perception) sRGB channels. This could be useful for presentations, because I’ve noticed the odd coloration makes the satellite images feel a bit detached from reality to me, like an over-saturated game or something. I imagine presentations featuring what a person feels like they would perceive if they were personally flying high overhead are more psychologically affecting, whether strictly scientifically relevant or not.

# Reflection

My brother is a forester, responsible for evaluating forest tracts for specific purposes: timber value, suitable habitat for specific wildlife, and most recently for forestry-based carbon credits. I think his industry could use more and better EO than what they currently do. For now, remote sensing is not directly applied to the tracts for which carbon credits are issued. Instead foresters directly measure every tree within randomly selected plots of the tracts. Because that’s expensive, it’s only done once every 5 years. The owners of the land are supposed to be paid for their carbon sequestration every year, so the administrators of the credits rely on predicted growth rates for the in-between years. Accumulated error in the prediction has to be made-up when the 5-year cycle ends. Maybe using EO data and a prediction model that would update every time the satellite passed by (or at least more frequently than every 5 years) could reduce the error and enable more consistent and reliable payments. 
